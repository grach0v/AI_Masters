{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3BBDJ1zR_sH"
      },
      "source": [
        "## **Домашняя работа №1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxcuiYyeL4t2"
      },
      "source": [
        "Нужно самостоятельно реализовать колоборативную фильтрацию методами:\n",
        "\n",
        "1. Knn нужно реализовать 2 базовых метода\n",
        "    1. Простой KNN (в библиотеке surprise называется KNNBasic)\n",
        "    2. Непараметрическая регрессия Надарайя-Ватсона (в библиотеке surprise называется KNNWithMeans)\n",
        "2. SVD-разложение\n",
        "    1. Метод SGD\n",
        "    2. Метод ALS\n",
        "3. SVD++\n",
        "\n",
        "С полученными методами нужно произвести следующие исследования:\n",
        "\n",
        "*   Нужно сравнить время работы всех реализованных алгоритмов.\n",
        "*   Нужно сравнить точность (в смысле RMSE) всех реализованных алгоритмов.\n",
        "    *   Качество (в смысле RMSE) kNN по параметру k\n",
        "    *   Качество (в смысле RMSE) SVD по числу факторов\n",
        "    *   Качество (в смысле RMSE) SVD по числу итераций в SGD\n",
        "\n",
        "В качестве датасэта можно использовать, например, https://grouplens.org/datasets/movielens/ (можно любой другой).\n",
        "\n",
        "Можно вдохновляться библиотеками (но не копировать код):\n",
        "https://implicit.readthedocs.io/en/latest/quickstart.html\n",
        "https://surprise.readthedocs.io/en/stable/getting_started.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFlSR_A4SDtt"
      },
      "source": [
        "## **Подготовка данных**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tyxBR5NML0k8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy\n",
        "from time import time\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.spatial.distance import euclidean, cosine\n",
        "from sklearn.metrics import pairwise_distances\n",
        "import matplotlib.pyplot as plt\n",
        "from numba import njit\n",
        "\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "QXRgi5-KNEha",
        "outputId": "141e1867-0bec-43be-e6a8-91d27ba2d1a6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>296</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1147880044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>306</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1147868817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>307</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1147868828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>665</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1147878820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>899</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1147868510</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userId  movieId  rating   timestamp\n",
              "0       1      296     5.0  1147880044\n",
              "1       1      306     3.5  1147868817\n",
              "2       1      307     5.0  1147868828\n",
              "3       1      665     5.0  1147878820\n",
              "4       1      899     3.5  1147868510"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Read data.\n",
        "path = 'ml-25m'\n",
        "\n",
        "df = pd.read_csv(f'{path}/ratings.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "top_users = df['userId'].value_counts()[:100_000]\n",
        "top_movies = df['movieId'].value_counts()[:100_000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Для упрощения вычислительной сложности и наглядности берем только наиболее популярные фильмы и юзеров. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df[df['userId'].isin(top_users) & df['movieId'].isin(top_movies)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Для удобства перенумеруем id "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "user_map = {value: new_value for new_value, value in enumerate(df['userId'].unique())}\n",
        "movie_map = {value: new_value for new_value, value in enumerate(df['movieId'].unique())}\n",
        "\n",
        "df['userId'] = df['userId'].map(user_map)\n",
        "df['movieId'] = df['movieId'].map(movie_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.drop_duplicates(subset=['userId', 'movieId'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DjIjm_PFNR5N"
      },
      "outputs": [],
      "source": [
        "def pivoter(data, user_column, item_column, rating_column, none_value):\n",
        "    # Pivots the data\n",
        "    return (\n",
        "        data.pivot(\n",
        "            index=user_column,\n",
        "            columns=item_column,\n",
        "            values=rating_column\n",
        "        ).fillna(none_value)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_test_pivoter(\n",
        "        df, test_size, \n",
        "        user_column, item_column, rating_column, \n",
        "        none_value\n",
        "    ):\n",
        "\n",
        "    train_df, test_df = train_test_split(df, test_size=test_size)\n",
        "\n",
        "    # add items from train to test and vice versa\n",
        "    # so that they have same shape matrices \n",
        "    train_df = pd.concat([\n",
        "        train_df,\n",
        "        test_df.assign(**{rating_column: none_value})\n",
        "    ]).drop_duplicates(subset=[user_column, item_column])\n",
        "\n",
        "    \n",
        "    train = pivoter(train_df, user_column, item_column, rating_column, none_value).to_numpy()\n",
        "    \n",
        "    train_df.dropna(inplace=True)\n",
        "    train_df.set_index(np.arange(len(train_df)), inplace=True)\n",
        "\n",
        "    return train_df, train, test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df, train, test_df = train_test_pivoter(\n",
        "    df, 0.33,\n",
        "    'userId', 'movieId', 'rating', \n",
        "    np.nan\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`train` - матрица со значениями \n",
        "пропуски заполнены именно `nan` \n",
        "\n",
        "`test_df` - датафрейм с парами юзер, фильм для которых надо предсказать значение."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVrnynBzOewg"
      },
      "source": [
        "## **Простой KNN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "В расстоянии нужно учитывать `nan`  \n",
        "Поэтому для L2 расстояния берется среднее отклонение по всем не пустым координатам  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "@njit(parallel=True)\n",
        "def my_euclidean(x, y):\n",
        "    ids = ~np.isnan(x) & ~np.isnan(y)\n",
        "    \n",
        "    if np.sum(ids) == 0:\n",
        "        return np.nan\n",
        "    \n",
        "    return np.sum((x[ids] - y[ids])**2) / np.sum(ids)\n",
        "\n",
        "@njit(parallel=True)\n",
        "def my_cosine(x, y):\n",
        "    ids = ~np.isnan(x) & ~np.isnan(y)\n",
        "    \n",
        "    if np.sum(ids) == 0:\n",
        "        return np.nan\n",
        "    \n",
        "    return (x[ids] @ y[ids]) / (np.linalg.norm(x[ids]) * np.linalg.norm(y[ids])) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "class KNN:\n",
        "    def __init__(self, k, based='user', metric='euclidean'):\n",
        "        \n",
        "        if based not in ('user', 'item'):\n",
        "            raise ValueError('Wrong based system')\n",
        "\n",
        "        self.k = k\n",
        "        self.based = based\n",
        "        self.metric = metric\n",
        "\n",
        "    def fit(self, train):\n",
        "        \n",
        "        if self.based == 'user':\n",
        "            pass\n",
        "\n",
        "        if self.based == 'item':\n",
        "            train = train.T\n",
        "\n",
        "        self.distances = pairwise_distances(\n",
        "            train, train, \n",
        "            force_all_finite='allow-nan', \n",
        "            metric=my_euclidean\n",
        "        )\n",
        "        self.neighbours = self.distances.argsort(axis=1)\n",
        "        self.train = train\n",
        "\n",
        "    def predict(self, test_data):\n",
        "        predictions = []\n",
        "        mean = np.nanmean(train)\n",
        "\n",
        "        if self.based == 'user':\n",
        "            iterator = test_data[['userId', 'movieId']].iterrows()\n",
        "\n",
        "        if self.based == 'item':\n",
        "            iterator = test_data[['movieId', 'userId']].iterrows()\n",
        "\n",
        "        for _, (user_id, item_id) in iterator:\n",
        "            watched = ~np.isnan(self.train[:, item_id])\n",
        "            watched = np.arange(len(watched))[watched]\n",
        "            watched = self.neighbours[user_id][np.isin(self.neighbours[user_id], watched)]\n",
        "\n",
        "            if np.sum(watched) == 0:\n",
        "                pred = mean\n",
        "            else:\n",
        "                pred = np.nanmean(self.train[watched][:10][:, item_id])\n",
        "\n",
        "            predictions.append(pred)\n",
        "\n",
        "        return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE of baseline 0.87\n"
          ]
        }
      ],
      "source": [
        "test_df['train_mean'] = train_df['rating'].mean()\n",
        "MAE = (test_df['train_mean'] - test_df['rating']).abs().mean()\n",
        "print(f'MAE of baseline {MAE:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = KNN(k=10)\n",
        "\n",
        "model.fit(train)\n",
        "preds = model.predict(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE of knn 0.74\n"
          ]
        }
      ],
      "source": [
        "test_df['knn_preds'] = preds\n",
        "MAE = (test_df['knn_preds'] - test_df['rating']).abs().mean()\n",
        "print(f'MAE of knn {MAE:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jquwezjHOvWu"
      },
      "source": [
        "## **Непараметрическая регрессия Надарайя-Ватсона**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "class KNN_NW:\n",
        "    def __init__(self, k, based='user', metric='euclidean'):\n",
        "        \n",
        "        if based not in ('user', 'item'):\n",
        "            raise ValueError('Wrong based system')\n",
        "\n",
        "        self.k = k\n",
        "        self.based = based\n",
        "        self.metric = metric\n",
        "\n",
        "    def fit(self, train):        \n",
        "        if self.based == 'user':\n",
        "            pass\n",
        "\n",
        "        if self.based == 'item':\n",
        "            train = train.T\n",
        "\n",
        "        self.distances = pairwise_distances(\n",
        "            train, train, \n",
        "            force_all_finite='allow-nan', \n",
        "            metric=my_euclidean\n",
        "        )\n",
        "        self.neighbours = self.distances.argsort(axis=1)\n",
        "        self.train = train\n",
        "\n",
        "    def predict(self, test_data):\n",
        "        predictions = []\n",
        "        total_mean = np.nanmean(train)\n",
        "\n",
        "        if self.based == 'user':\n",
        "            iterator = test_data[['userId', 'movieId']].iterrows()\n",
        "\n",
        "        if self.based == 'item':\n",
        "            iterator = test_data[['movieId', 'userId']].iterrows()\n",
        "\n",
        "        for _, (user_id, item_id) in iterator:\n",
        "            watched = ~np.isnan(self.train[:, item_id])\n",
        "            watched = np.arange(len(watched))[watched]\n",
        "            watched = self.neighbours[user_id][np.isin(self.neighbours[user_id], watched)]\n",
        "\n",
        "            with warnings.catch_warnings():\n",
        "                warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
        "                \n",
        "                mean = np.nanmean(self.train[user_id])\n",
        "                num = np.nansum(self.distances[user_id, watched] * (train[watched, item_id] - mean))\n",
        "                den = np.nansum(self.distances[user_id, watched])\n",
        "\n",
        "            if np.isnan(mean):\n",
        "                mean = total_mean\n",
        "\n",
        "            if np.abs(den) > 1e-5:\n",
        "                pred = mean + num / den\n",
        "            else:\n",
        "                pred = mean\n",
        "\n",
        "            predictions.append(pred)\n",
        "\n",
        "        return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = KNN_NW(k=10)\n",
        "\n",
        "model.fit(train)\n",
        "preds = model.predict(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE of knn 0.81\n"
          ]
        }
      ],
      "source": [
        "test_df['knn_nw_preds'] = preds\n",
        "MAE = (test_df['knn_nw_preds'] - test_df['rating']).abs().mean()\n",
        "print(f'MAE of knn_nw {MAE:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoFw0WDQQt8k"
      },
      "source": [
        "## **SVD разложение методами: SGD, ALS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SVD:\n",
        "    def __init__(self, emb_size, n_users, n_items):\n",
        "\n",
        "        self.emb_size = emb_size\n",
        "        self.b_user = np.random.normal(size=n_users)\n",
        "        self.b_item = np.random.normal(size=n_items)\n",
        "\n",
        "        self.Q = np.random.normal(size=(n_users, emb_size))\n",
        "        self.P = np.random.normal(size=(n_items, emb_size))\n",
        "\n",
        "    \n",
        "    def train_sgd(self, train_df, lr, n_epochs, reg_lambda):\n",
        "        \n",
        "        self.mean = train_df['rating'].mean()\n",
        "\n",
        "        for _ in range(n_epochs):\n",
        "            iterator = train_df[['userId', 'movieId', 'rating']].itertuples()\n",
        "            for _, user_id, item_id, rating in iterator:\n",
        "                pred = (\n",
        "                    self.mean + \n",
        "                    self.b_user[user_id] + self.b_item[item_id] +\n",
        "                    self.Q[user_id] @ self.P[item_id]\n",
        "                ) \n",
        "\n",
        "                err = rating - pred\n",
        "                \n",
        "                self.b_user[user_id] += lr * (err - reg_lambda * self.b_user[user_id])\n",
        "                self.b_item[item_id] += lr * (err - reg_lambda * self.b_item[item_id])\n",
        "\n",
        "                self.Q[user_id] += lr * (err * self.P[item_id] - reg_lambda * self.Q[user_id])\n",
        "                self.P[item_id] += lr * (err * self.Q[user_id] - reg_lambda * self.P[item_id])\n",
        "\n",
        "    def train_als(self, train, n_epochs, alpha):\n",
        "        \n",
        "        self.mean = np.nanmean(train)\n",
        "\n",
        "        reg_ones = alpha * np.eye(self.emb_size + 1)\n",
        "\n",
        "        for _ in range(n_epochs):\n",
        "            for user_id in range(train.shape[0]):\n",
        "                ids = ~np.isnan(train[user_id])\n",
        "\n",
        "                ratings = train[user_id, ids]\n",
        "                movie_emb = self.P[ids]\n",
        "\n",
        "                # Add column of ones\n",
        "                n_watched = len(movie_emb)\n",
        "                movie_emb = np.hstack([movie_emb, np.ones((n_watched, 1))])\n",
        "        \n",
        "                sol = np.linalg.inv(movie_emb.T @ movie_emb + reg_ones) @ movie_emb.T @ (ratings - self.mean)\n",
        "                self.Q[user_id] = sol[:-1].copy()\n",
        "                self.b_user[user_id] = sol[-1]\n",
        "\n",
        "            for item_id in range(train.shape[1]):\n",
        "                ids = ~np.isnan(train[:, item_id])\n",
        "\n",
        "                ratings = train[ids, item_id]\n",
        "                user_emb = self.Q[ids]\n",
        "\n",
        "                # Add column of ones\n",
        "                n_watched = len(user_emb)\n",
        "                user_emb = np.hstack([user_emb, np.ones((n_watched, 1))])\n",
        "\n",
        "                sol = np.linalg.inv(user_emb.T @ user_emb + reg_ones) @ user_emb.T @ (ratings - self.mean)\n",
        "                self.P[item_id] = sol[:-1].copy()\n",
        "                self.b_item[item_id] = sol[-1]\n",
        "\n",
        "    def predict(self, test_df):\n",
        "        \n",
        "        preds = []\n",
        "        for _, user_id, item_id in test_df[['userId', 'movieId']].itertuples():\n",
        "            preds.append(\n",
        "                self.mean + \n",
        "                self.b_user[user_id] + self.b_item[item_id] + \n",
        "                self.Q[user_id] @ self.P[item_id]\n",
        "            )\n",
        "        \n",
        "        return preds\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = SVD(emb_size=20, n_users=train.shape[0], n_items=train.shape[1])\n",
        "model.train_sgd(train_df, lr=0.01, n_epochs=50, reg_lambda=0.1)\n",
        "preds = model.predict(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE of knn 0.74\n"
          ]
        }
      ],
      "source": [
        "test_df['svd_sgd'] = preds\n",
        "MAE = (test_df['svd_sgd'] - test_df['rating']).abs().mean()\n",
        "print(f'MAE of svd_sgd {MAE:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = SVD(emb_size=20, n_users=train.shape[0], n_items=train.shape[1])\n",
        "model.train_als(train, n_epochs=10, alpha=1)\n",
        "preds = model.predict(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE of knn 1.04\n"
          ]
        }
      ],
      "source": [
        "test_df['svd_als'] = preds\n",
        "MAE = (test_df['svd_als'] - test_df['rating']).abs().mean()\n",
        "print(f'MAE of svd_als {MAE:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z42O-XkLRHhG"
      },
      "source": [
        "## **SVD++**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SVDPlus:\n",
        "    def __init__(self, emb_size, n_users, n_items):\n",
        "\n",
        "        self.emb_size = emb_size\n",
        "        self.b_user = np.random.normal(size=n_users)\n",
        "        self.b_item = np.random.normal(size=n_items)\n",
        "        self.y = np.random.normal(size=n_items)\n",
        "\n",
        "        self.Q = np.random.normal(size=(n_users, emb_size))\n",
        "        self.P = np.random.normal(size=(n_items, emb_size))\n",
        "\n",
        "    \n",
        "    def train_sgd(self, train_df, train, lr, n_epochs, reg_lambda):\n",
        "        \n",
        "        self.mean = train_df['rating'].mean()\n",
        "\n",
        "        for _ in range(n_epochs):\n",
        "            iterator = train_df[['userId', 'movieId', 'rating']].itertuples()\n",
        "            for _, user_id, item_id, rating in iterator:\n",
        "                \n",
        "                ids = ~np.isnan(train[user_id])\n",
        "\n",
        "                with warnings.catch_warnings():\n",
        "                    warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
        "                    sum_y_i = np.nansum(self.y[ids])\n",
        "                            \n",
        "                var_control = np.sqrt(np.sum(ids)) if sum_y_i != 0 else 1\n",
        "\n",
        "                pred = (\n",
        "                    self.mean + \n",
        "                    self.b_user[user_id] + self.b_item[item_id] +\n",
        "                    self.Q[user_id] @ (self.P[item_id] + sum_y_i / var_control)\n",
        "                ) \n",
        "\n",
        "                err = rating - pred\n",
        "                \n",
        "                self.b_user[user_id] += lr * (err - reg_lambda * self.b_user[user_id])\n",
        "                self.b_item[item_id] += lr * (err - reg_lambda * self.b_item[item_id])\n",
        "\n",
        "                self.Q[user_id] += lr * (err * self.P[item_id] - reg_lambda * self.Q[user_id])\n",
        "                self.P[item_id] += lr * (err * self.Q[user_id] - reg_lambda * self.P[item_id])\n",
        "\n",
        "                self.y[ids] += lr * (err * np.sum(self.Q[user_id]) / var_control - reg_lambda * self.y[ids])\n",
        "\n",
        "\n",
        "    def predict(self, test_df):\n",
        "        \n",
        "        preds = []\n",
        "        for _, user_id, item_id in test_df[['userId', 'movieId']].itertuples():\n",
        "            preds.append(\n",
        "                self.mean + \n",
        "                self.b_user[user_id] + self.b_item[item_id] + \n",
        "                self.Q[user_id] @ self.P[item_id]\n",
        "            )\n",
        "        \n",
        "        return preds\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = SVDPlus(emb_size=20, n_users=train.shape[0], n_items=train.shape[1])\n",
        "model.train_sgd(train_df, train, lr=0.005, n_epochs=10, reg_lambda=10)\n",
        "preds = model.predict(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE of svd_plus 0.84\n"
          ]
        }
      ],
      "source": [
        "test_df['svd_plus'] = preds\n",
        "MAE = (test_df['svd_plus'] - test_df['rating']).abs().mean()\n",
        "print(f'MAE of svd_plus {MAE:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
